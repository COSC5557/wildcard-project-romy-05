# -*- coding: utf-8 -*-
"""Wildcard_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uf-rQZP8LSMApCcdMT8KcVuuYq51Xe60
"""

import pandas as pd
import numpy as np

dataset = pd.read_csv('/content/X1_dataset.csv')

dataset

X=dataset.drop(['formation'], axis=1, inplace=False)
Y=dataset['formation']

X

print(X.shape)

X.info()

X.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

corr_related = X.corr()

plt.figure(figsize=(7,7))
sns.heatmap(corr_related, cbar=True, square=True, fmt = '.1f', annot = True, annot_kws={'size':8}, cmap = 'Blues')

non_corr = X.drop(['Depth','Hook Load','Block Height','ROP - Average','Top Drive Torque','Diff Press','Flow Out Percent','Pump Pressure','Pump SPM - Total','Bit Size','D-EXPONENT','Gamma Ray','Mud Weight In'], axis=1)

non_corr

no_cor = non_corr.corr()

plt.figure(figsize=(7,7))
sns.heatmap(no_cor, cbar=True, square=True, fmt = '.1f', annot = True, annot_kws={'size':8}, cmap = 'Blues')

Y.value_counts()

from imblearn.over_sampling import SMOTE

# Apply SMOTE for oversampling
oversample = SMOTE(random_state=42)
X_resampled, y_resampled = oversample.fit_resample(non_corr, Y)

from sklearn.preprocessing import MinMaxScaler

# Initialize MinMaxScaler
scaler = MinMaxScaler()

# Fit and transform the dataset
normalized_input_data = scaler.fit_transform(X_resampled)

# Convert the normalized dataset back to a DataFrame (optional)
normalized_input_data = pd.DataFrame(normalized_input_data, columns=X_resampled.columns)

# Summary statistics of the normalized dataset
print("Summary statistics of the normalized dataset:")
print(normalized_input_data.describe())

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score
from scipy.stats import randint

# Define inner and outer cross-validation folds
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Define the parameter distributions for hyperparameter tuning
param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': randint(2, 20)
}

# Initialize lists to store nested cross-validation scores
nested_scores_rf = []

for train_index, test_index in outer_cv.split(X_resampled):
    X_train, X_test = normalized_input_data.iloc[train_index], normalized_input_data.iloc[test_index]
    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]


# Outer cross-validation loop
#for train_index, test_index in outer_cv.split(normalized_input_data):
  #  X_train, X_test = normalized_input_data[train_index], normalized_input_data[test_index]
  #  y_train, y_test = y_resampled[train_index], y_resampled[test_index]

    # Inner cross-validation loop for hyperparameter tuning
    random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)
    random_search.fit(X_train, y_train)

    # Get the best model from inner CV
    best_model = random_search.best_estimator_

    # Fit the best model on the training data
    best_model.fit(X_train, y_train)

    # Evaluate the best model on the test set
    y_pred = best_model.predict(X_test)

    # Calculate accuracy and store the result
    accuracy = accuracy_score(y_test, y_pred)
    nested_scores_rf.append(accuracy)

# Calculate mean accuracy score from nested CV
mean_nested_score_rf = np.mean(nested_scores_rf)
print("Mean Accuracy Score from Nested Cross-Validation (Random Forest):", mean_nested_score_rf)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import KFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score
from scipy.stats import randint
import numpy as np

# Define inner and outer cross-validation folds
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Define the parameter distributions for hyperparameter tuning for KNN
param_dist = {
    'n_neighbors': randint(1, 20),
    'weights': ['uniform', 'distance'],
    'p': [1, 2]
}

# Initialize lists to store nested cross-validation scores for KNN
nested_scores_knn = []

for train_index, test_index in outer_cv.split(X_resampled):
    X_train, X_test = normalized_input_data.iloc[train_index], normalized_input_data.iloc[test_index]
    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]

    # Perform RandomizedSearchCV for hyperparameter tuning
    random_search = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)
    random_search.fit(X_train, y_train)

    # Get the best model from inner CV
    best_model = random_search.best_estimator_

    # Fit the best model on the training data
    best_model.fit(X_train, y_train)

    # Evaluate the best model on the test set
    y_pred = best_model.predict(X_test)

    # Calculate accuracy and store the result
    accuracy = accuracy_score(y_test, y_pred)
    nested_scores_knn.append(accuracy)

# Calculate mean accuracy score from nested CV for KNN
mean_nested_score_knn = np.mean(nested_scores_knn)
print("Mean Accuracy Score from Nested Cross-Validation (KNN):", mean_nested_score_knn)

from xgboost import XGBClassifier
from sklearn.model_selection import cross_val_score, KFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score
from scipy.stats import randint

# Define inner and outer cross-validation folds
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Define the parameter distributions for hyperparameter tuning for XGBoost
param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 10),
    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 1, 5],
    'reg_alpha': [0, 0.1, 0.5, 1.0],
    'reg_lambda': [0, 1, 5, 10]
}

# Initialize lists to store nested cross-validation scores for XGBoost
nested_scores_xgb = []

for train_index, test_index in outer_cv.split(X_resampled):
    X_train, X_test = normalized_input_data.iloc[train_index], normalized_input_data.iloc[test_index]
    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]

    # Inner cross-validation loop for hyperparameter tuning
    random_search = RandomizedSearchCV(XGBClassifier(random_state=42), param_distributions=param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)
    random_search.fit(X_train, y_train)

    # Get the best model from inner CV
    best_model = random_search.best_estimator_

    # Fit the best model on the training data
    best_model.fit(X_train, y_train)

    # Evaluate the best model on the test set
    y_pred = best_model.predict(X_test)

    # Calculate accuracy and store the result
    accuracy = accuracy_score(y_test, y_pred)
    nested_scores_xgb.append(accuracy)

# Calculate mean accuracy score from nested CV for XGBoost
mean_nested_score_xgb = np.mean(nested_scores_xgb)
print("Mean Accuracy Score from Nested Cross-Validation (XGBoost):", mean_nested_score_xgb)

from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import StackingClassifier
from sklearn.model_selection import KFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score
from scipy.stats import randint
import numpy as np

# Define inner and outer cross-validation folds
inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)
outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)

# Define the parameter distributions for hyperparameter tuning for each base learner
rf_param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': randint(2, 20)
}

knn_param_dist = {
    'n_neighbors': randint(1, 20),
    'weights': ['uniform', 'distance'],
    'p': [1, 2]
}

xgb_param_dist = {
    'n_estimators': randint(50, 200),
    'max_depth': randint(3, 10),
    'learning_rate': [0.001, 0.01, 0.1, 0.2, 0.3],
    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],
    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],
    'gamma': [0, 1, 5],
    'reg_alpha': [0, 0.1, 0.5, 1.0],
    'reg_lambda': [0, 1, 5, 10]
}


# Initialize base learners with hyperparameter tuning
rf_base = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_distributions=rf_param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)
knn_base = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=knn_param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)

# Initialize meta-learner (XGBoost) with hyperparameter tuning
xgb_meta = RandomizedSearchCV(XGBClassifier(random_state=42), param_distributions=xgb_param_dist, n_iter=50, cv=inner_cv, scoring='accuracy', random_state=42)

# Define the stacking classifier with XGBoost as the meta-learner
stacking_clf = StackingClassifier(estimators=[('rf', rf_base), ('knn', knn_base)], final_estimator=xgb_meta)

# Initialize list to store nested cross-validation scores for stacking
nested_scores_stacking = []

for train_index, test_index in outer_cv.split(X_resampled):
    X_train, X_test = normalized_input_data.iloc[train_index], normalized_input_data.iloc[test_index]
    y_train, y_test = y_resampled.iloc[train_index], y_resampled.iloc[test_index]

    # Fit the base learners with hyperparameter tuning on the training data
    rf_base.fit(X_train, y_train)
    knn_base.fit(X_train, y_train)

    # Get the best base models
    best_rf_model = rf_base.best_estimator_
    best_knn_model = knn_base.best_estimator_

    # Fit the stacking classifier on the training data
    stacking_clf.fit(X_train, y_train)

    # Predict on the test set
    y_pred = stacking_clf.predict(X_test)

    # Calculate accuracy and store the result
    accuracy = accuracy_score(y_test, y_pred)
    nested_scores_stacking.append(accuracy)

# Calculate mean accuracy score from nested CV for stacking
mean_nested_score_stacking = np.mean(nested_scores_stacking)
print("Mean Accuracy Score from Nested Cross-Validation (Stacking):", mean_nested_score_stacking)